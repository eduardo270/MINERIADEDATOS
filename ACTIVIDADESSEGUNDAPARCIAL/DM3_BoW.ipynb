{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM3.BoW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BoW Mineria de Datos\n",
        "\n",
        "\n",
        "*   Estudiante: Inca Cruz Carlos Eduardo"
      ],
      "metadata": {
        "id": "xOk9UfGfvw7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar pyspark"
      ],
      "metadata": {
        "id": "z-mYLbsSal1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get package\n",
        "!wget https://downloads.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop2.7.tgz\n",
        "!tar -xvzf spark-3.2.0-bin-hadoop2.7.tgz\n",
        "!pip install findspark\n",
        "#env vars\n",
        "import os\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.0-bin-hadoop2.7\"\n",
        "#start spark\n",
        "import findspark\n",
        "findspark.init()\n",
        "#import spark session\n",
        "from pyspark.sql import SparkSession\n",
        "#build app\n",
        "spark = SparkSession.builder.appName(\"PySpark\").getOrCreate()\n",
        "print(spark.sparkContext.appName)\n",
        "#create sparkcontext\n",
        "sc=spark.sparkContext\n",
        "#clear output\n",
        "from google.colab import output\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "SBXHO3iaaorc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baf Of Words"
      ],
      "metadata": {
        "id": "mGlFKHwVSw8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Bag Of Words**"
      ],
      "metadata": {
        "id": "RkVH1Py6fQt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def RemoverCaracteres(texto):\n",
        "    return re.sub(r'[^A-Za-z0-9 ]', '', texto).strip().lower()"
      ],
      "metadata": {
        "id": "hbvaFheUfRXs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import operator\n",
        "\n",
        "import re\n",
        "# Remover Caracteres\n",
        "def RemoverCaracteres(texto):\n",
        "    return re.sub(r'[^A-Za-z0-9 ]', '', texto).strip().lower()\n",
        "# Leer archivo de texto\n",
        "archivo = os.path.join('.', 'pg100.txt') \n",
        "\n",
        "#introducir el texto\n",
        "shakesRDD = (sc.textFile(archivo, 8).map(RemoverCaracteres))\n",
        "def Tokenizar(lista):\n",
        "    return [i for i in lista.split(\" \")]\n",
        "\n",
        "shakesRDD = shakesRDD.flatMap(Tokenizar)\n",
        "# Eliminar palabras vacias\n",
        "shakesRDD = shakesRDD.filter(lambda x : len(x) !=0)\n",
        "# Eliminar palabras con longitudes menores a dos\n",
        "shakesRDD = shakesRDD.filter(lambda x : len(x) > 2)\n",
        "# Asignar el 1 a cada palabra para contar la frecuencia\n",
        "shakesRDD = shakesRDD.map(lambda x : (x,1))\n",
        "# Eliminar palabras repetidas\n",
        "shakesRDD = shakesRDD.reduceByKey(lambda a,b: a+b)\n",
        "# Obtener las claves\n",
        "shakesRDD = shakesRDD.map(lambda x: x[0])\n",
        "# Tomar solo 50 datos\n",
        "print(shakesRDD.take(50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfPP-_iCeLfP",
        "outputId": "cc051a4e-efef-40ec-a2fd-840683c1abda"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['other', 'whatsoever', 'gutenberg', 'are', 'check', 'where', 'using', '2017', 'february', 'set', 'encoding', 'start', 'ends', 'cleopatra', 'like', 'errors', 'sixth', 'john', 'julius', 'lost', 'macbeth', 'nights', 'ado', 'othello', 'twelfth', 'two', 'passionate', 'thereby', 'but', 'tender', 'selfsubstantial', 'fuel', 'self', 'now', 'when', 'besiege', 'praise', 'deservd', 'sum', 'succession', 'repair', 'unbless', 'husbandry', 'why', 'free', 'beauteous', 'bounteous', 'profitless', 'yet', 'work']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Obtener frecuencia**"
      ],
      "metadata": {
        "id": "OXZy59IUiw3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import operator\n",
        "# Leer archivo de texto\n",
        "archivo = os.path.join('.', 'pg100.txt') \n",
        "\n",
        "#introducir el texto\n",
        "shakesRDD = (sc.textFile(archivo, 8).map(RemoverCaracteres))\n",
        "\n",
        "shakesRDD = shakesRDD.flatMap(Tokenizar)\n",
        "# Eliminar palabras vacias\n",
        "shakesRDD = shakesRDD.filter(lambda x : len(x) !=0)\n",
        "# Eliminar palabras con longitudes menores a dos\n",
        "shakesRDD = shakesRDD.filter(lambda x : len(x) > 2)\n",
        "# Asignar el 1 a cada palabra para contar la frecuencia\n",
        "shakesRDD = shakesRDD.map(lambda x : (x,1))\n",
        "# Obtener la frecuencia\n",
        "shakesRDD = shakesRDD.reduceByKey(lambda a,b: a+b)\n",
        "#Mostrar las palabras del bow\n",
        "shakesRDD = shakesRDD.map(lambda x: (x[0],x[1]))\n",
        "# Tomar solo 50 datos\n",
        "print(shakesRDD.take(50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YZj1nqAiuNn",
        "outputId": "feedd09c-01ed-4ac5-a4d1-d38a593c553a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('other', 723), ('whatsoever', 17), ('gutenberg', 36), ('are', 3730), ('check', 32), ('where', 1372), ('using', 14), ('2017', 3), ('february', 2), ('set', 509), ('encoding', 1), ('start', 39), ('ends', 54), ('cleopatra', 264), ('like', 1928), ('errors', 15), ('sixth', 37), ('john', 534), ('julius', 19), ('lost', 287), ('macbeth', 285), ('nights', 71), ('ado', 20), ('othello', 326), ('twelfth', 3), ('two', 758), ('passionate', 11), ('thereby', 27), ('but', 6776), ('tender', 156), ('selfsubstantial', 1), ('fuel', 5), ('self', 144), ('now', 3011), ('when', 2225), ('besiege', 11), ('praise', 191), ('deservd', 39), ('sum', 58), ('succession', 17), ('repair', 48), ('unbless', 1), ('husbandry', 15), ('why', 1552), ('free', 204), ('beauteous', 44), ('bounteous', 19), ('profitless', 3), ('yet', 1754), ('work', 236)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Obtener N-Gramas**"
      ],
      "metadata": {
        "id": "qNc1VzdrgzVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obtenNGramas(sentence, n):\n",
        "    l1=[x for x in sentence.split(\" \")]\n",
        "    return [l1[i:i+n] for i in range(len(l1)-(n-1))]\n"
      ],
      "metadata": {
        "id": "fg6cZoT5mgSj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataRDD=sc.parallelize(['this is a foo bar sentences and i want to ngramize it','this is a foo bar sentences and i want to ngramize it','this is a foo bar sentences and i want to ngramize it'],8)\n",
        "dataRDD2 = dataRDD.map(lambda x: (x,str(obtenNGramas(x,3))))\n",
        "print(dataRDD2.collect())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d4fe2a-504a-4e60-a9f0-395e43a03f2d",
        "id": "I-y6XzkkukRq"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('this is a foo bar sentences and i want to ngramize it', \"[['this', 'is', 'a'], ['is', 'a', 'foo'], ['a', 'foo', 'bar'], ['foo', 'bar', 'sentences'], ['bar', 'sentences', 'and'], ['sentences', 'and', 'i'], ['and', 'i', 'want'], ['i', 'want', 'to'], ['want', 'to', 'ngramize'], ['to', 'ngramize', 'it']]\"), ('this is a foo bar sentences and i want to ngramize it', \"[['this', 'is', 'a'], ['is', 'a', 'foo'], ['a', 'foo', 'bar'], ['foo', 'bar', 'sentences'], ['bar', 'sentences', 'and'], ['sentences', 'and', 'i'], ['and', 'i', 'want'], ['i', 'want', 'to'], ['want', 'to', 'ngramize'], ['to', 'ngramize', 'it']]\"), ('this is a foo bar sentences and i want to ngramize it', \"[['this', 'is', 'a'], ['is', 'a', 'foo'], ['a', 'foo', 'bar'], ['foo', 'bar', 'sentences'], ['bar', 'sentences', 'and'], ['sentences', 'and', 'i'], ['and', 'i', 'want'], ['i', 'want', 'to'], ['want', 'to', 'ngramize'], ['to', 'ngramize', 'it']]\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Obtener TF IDF**"
      ],
      "metadata": {
        "id": "96lD-w8BdECw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Modulo remover Signos de puntuacion\n",
        "import re\n",
        "import math\n",
        "from pyspark.sql.functions import *\n",
        "import os.path\n",
        "\n",
        "\n",
        "#almacenamos nuestros datos en un arreglo con un indice que nos indique  el numero de linea en el cual se encuentra\n",
        "data=[(1,\"messi messi messi ronaldo ronaldo balon\"),(2,\"messi ronaldo futbol futbol futbol\")]\n",
        "# Los elementos de la lista se copian para formar un conjunto de datos distribuido que se puede operar en paralelo\n",
        "lineas=sc.parallelize(data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Contar la frecuencia de aparicion de cada palabra \n",
        "# en la oracion en una determinada linea\n",
        "frecuenciaRDD=lineas.flatMap(lambda x: [((x[0],i),1) for i in x[1].split()])\n",
        "palabraoracion=frecuenciaRDD.reduceByKey(lambda x,y:x+y)\n",
        "\n",
        "\n",
        "# Diccionario de palabras totales para hallar el tf\n",
        "# Tiene como clave la palabra(token) y como valor\n",
        "# el numero de veces que aparece en todos los documentos\n",
        "diccionariotokens=lineas.flatMap(lambda x: [(i,1) for i in x[1].split()])\n",
        "mpdic=diccionariotokens.reduceByKey(lambda x,y:x+y)\n",
        "mpdict=dict(mpdic.collect())\n",
        "# Mostrando frecuencia de aparicion de palabras en todo el documento\n",
        "\n",
        "\n",
        "# Una vez obtenido el numero de veces que aparece una \n",
        "# palabra en todo el documento y el numero de palabras\n",
        "# que tiene el documento\n",
        "# Hallamos el tf con la formula\n",
        "#tf=reduce.map(lambda x: (x[0][1],(x[0][0],1+math.log10(x[1]/mpdict[x[0][1]]))))\n",
        "tf=palabraoracion.map(lambda x: (x[0][1],(x[0][0],1+math.log10(x[1]/mpdict[x[0][1]]))))\n",
        "tfshow=tf.map(lambda x: (x[0],x[1][1]))\n",
        "#Aquí, la clave será el token y su valor será el identificador TF del \n",
        "#documento para ese token junto con un contador de 1\n",
        "frecp=palabraoracion.map(lambda x: (x[0][1],(x[0][0],x[1],1)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Obtenemos en cuantos documentos aparece una determinada palabra\n",
        "map4=frecp.map(lambda x:(x[0],x[1][2]))\n",
        "palabrapordocumento=map4.reduceByKey(lambda x,y:x+y)\n",
        "\n",
        "\n",
        "#Una vez obtenidos en cuantos documentos aparece una palabra en x[1]\n",
        "# y el numero total de documentos en el corpus en len(data)\n",
        "idf=palabrapordocumento.map(lambda x: (x[0],math.log10 (1+len(data)/x[1]) ))\n",
        "\n",
        "\n",
        "tfshow.toDF([\"Token\",\"TF\"]).show()\n",
        "idf.toDF([\"Token\",\"IDF\"]).show()\n",
        "#Unimos los valores de tf con itf con la funcion join\n",
        "rdd=tf.join(idf)\n",
        "\n",
        "# multiplicamos tf*itf\n",
        "rdd=rdd.map(lambda x: (x[1][0][0],(x[0],x[1][0][1],x[1][1],x[1][0][1]*x[1][1]))).sortByKey()\n",
        "\n",
        "# Formatemos para mostrar \n",
        "rdd=rdd.map(lambda x: (x[0],x[1][0],x[1][1],x[1][2],x[1][3]))\n",
        "\n",
        "rdd.toDF([\"Nro de Linea\",\"Palabra\",\"TF\",\"IDF\",\"TF*IDF\"]).show()"
      ],
      "metadata": {
        "id": "YPEBek5pdBEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc9c5be-bbe4-4ba1-c582-7bf5c5c0a37b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|  Token|                TF|\n",
            "+-------+------------------+\n",
            "|ronaldo|0.8239087409443188|\n",
            "|  balon|               1.0|\n",
            "|  messi|0.3979400086720376|\n",
            "|  messi|0.8750612633917001|\n",
            "|ronaldo|0.5228787452803375|\n",
            "| futbol|               1.0|\n",
            "+-------+------------------+\n",
            "\n",
            "+-------+-------------------+\n",
            "|  Token|                IDF|\n",
            "+-------+-------------------+\n",
            "|  messi| 0.3010299956639812|\n",
            "|ronaldo| 0.3010299956639812|\n",
            "|  balon|0.47712125471966244|\n",
            "| futbol|0.47712125471966244|\n",
            "+-------+-------------------+\n",
            "\n",
            "+------------+-------+------------------+-------------------+-------------------+\n",
            "|Nro de Linea|Palabra|                TF|                IDF|             TF*IDF|\n",
            "+------------+-------+------------------+-------------------+-------------------+\n",
            "|           1|ronaldo|0.8239087409443188| 0.3010299956639812|0.24802124471398448|\n",
            "|           1|  messi|0.8750612633917001| 0.3010299956639812| 0.2634196883245214|\n",
            "|           1|  balon|               1.0|0.47712125471966244|0.47712125471966244|\n",
            "|           2|ronaldo|0.5228787452803375| 0.3010299956639812|0.15740218642452794|\n",
            "|           2|  messi|0.3979400086720376| 0.3010299956639812|0.11979187908506812|\n",
            "|           2| futbol|               1.0|0.47712125471966244|0.47712125471966244|\n",
            "+------------+-------+------------------+-------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}